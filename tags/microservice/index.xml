<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>microservice on Norwegian Wood</title>
    <link>/tags/microservice/</link>
    <description>Recent content in microservice on Norwegian Wood</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-cn</language>
    <copyright>Jzh</copyright>
    <lastBuildDate>Tue, 09 Aug 2022 21:41:53 +0800</lastBuildDate><atom:link href="/tags/microservice/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>使用 Seata 处理分布式事务</title>
      <link>/posts/2022/08/using-seata-to-process-distributed-transactions/</link>
      <pubDate>Tue, 09 Aug 2022 21:41:53 +0800</pubDate>
      
      <guid>/posts/2022/08/using-seata-to-process-distributed-transactions/</guid>
      <description>关于分布式事务 ​分布式系统会把一个应用系统拆分为可独立部署的多个服务，因此需要服务与服务之间远程协作才能完成事务操作。
这种分布式系统环境下由不同的服务之间通过网络远程协作完成事务称之为分布式事务。
例如用户下一个订单，需要首先创建订单，然后删减库存，接着扣除用户的金钱，最后完成订单。这个过程中，每个操作都可以作为一个微服务，每个微服务操作对应的数据库，而各个数据库可能分布在不同机器上，那么分布式事务就产生了，我们要确保一个事务被正确地处理，必须解决好分布式事务的数据提交与回滚。
关于Seata Seata 是一款开源的分布式事务解决方案，致力于提供高性能和简单易用的分布式事务服务。Seata 将为用户提供了 AT、TCC、SAGA 和 XA 事务模式，为用户打造一站式的分布式解决方案。（来源官网）
TC (Transaction Coordinator) - 事务协调者：
维护全局和分支事务的状态，驱动全局事务提交或回滚。
TM (Transaction Manager) - 事务管理器：
定义全局事务的范围：开始全局事务、提交或回滚全局事务。
RM (Resource Manager) - 资源管理器：
管理分支事务处理的资源，与TC交谈以注册分支事务和报告分支事务的状态，并驱动分支事务提交或回滚。
开始编码测试 架构说明 开启三个微服务，创建订单服务，删减库存服务，扣除用户金钱服务，均注册到nacos。
由订单服务作为入口，首先创建订单，然后删减库存，最后扣钱，完成订单，各个服务数据存取操作均处于不同数据库中。
使用seata作为分布式事务解决方案，也注册到nacos中。
配置Seata环境 一、下载Seata1.0.0
二、建seata表，sql链接
三、修改配置
(1) registry.conf:
type修改为nacos
1registry { 2 # file 、nacos 、eureka、redis、zk、consul、etcd3、sofa 3 type = &amp;#34;nacos&amp;#34; 4 5 nacos { 6 serverAddr = &amp;#34;localhost:8848&amp;#34; 7 namespace = &amp;#34;&amp;#34; 8 cluster = &amp;#34;default&amp;#34; 9 } 10.</description>
    </item>
    
    <item>
      <title>Sentinel 使用记录</title>
      <link>/posts/2022/08/sentinel-usage-record/</link>
      <pubDate>Mon, 08 Aug 2022 17:46:49 +0800</pubDate>
      
      <guid>/posts/2022/08/sentinel-usage-record/</guid>
      <description>Sentinel是什么 Sentinel 是面向分布式、多语言异构化服务架构的流量治理组件，主要以流量为切入点，从流量路由、流量控制、流量整形、熔断降级、系统自适应过载保护、热点流量防护等多个维度来帮助开发者保障微服务的稳定性。（来源于官方文档）
个人使用感觉：类似于Hystrix，使用上感觉比Hystrix更容易，功能也更强大。
架构说明 两个生产者服务运行在9001和9002端口，一个消费者服务运行在80端口，均注册到nacos，消费者调用两个生产者的服务。
将消费者服务注册到sentinel中，通过修改一些规则进行测试。
controller下的方法指定好处理服务限流，降级或熔断等的方法blockHandler，以及处理未知异常的fallback方法，通过指定class的方法避免代码膨胀。
service下的方法指定好关于生产者的服务限流，降级或熔断等的处理方法。
代码编写记录 生产者端 一、配置
关于nacos的配置省略，只记录sentinel的配置：
1spring: 2 application: 3 name: nacos-payment-provider 4 cloud: 5 sentinel: 6 transport: 7 dashboard: localhost:8080 8 port: 8179 二、controller编写
1@RestController 2@Slf4j 3public class PaymentController { 4 @Value(&amp;#34;${server.port}&amp;#34;) 5 private String port; 6 7 @GetMapping(&amp;#34;/payment/nacos/info&amp;#34;) 8 public String paymentInfo() { 9 return &amp;#34;port: &amp;#34; + port; 10 } 11} 返回对应端口，方便测试负载均衡。
消费者端 一、配置
1spring: 2 application: 3 name: nacos-order-consumer 4 sentinel: 5 transport: 6 dashboard: localhost:8080 7 port: 8179 8feign: 9 sentinel: 10 enabled: true 注意要开启feign的sentinel支持。</description>
    </item>
    
    <item>
      <title>Docker-compose 快速配置 nacos 集群环境</title>
      <link>/posts/2022/08/docker-compose-quickly-configures-nacos-cluster-environment/</link>
      <pubDate>Sun, 07 Aug 2022 16:02:27 +0800</pubDate>
      
      <guid>/posts/2022/08/docker-compose-quickly-configures-nacos-cluster-environment/</guid>
      <description>前言 总体架构说明 在一台CentOS主机上部署，版本为7.9，IP为192.168.1.127。
通过docker创建三台nacos环境的机器，端口均运行在8848，分别映射到主机的8848，8858，8868端口上，名称（hostname）分别为nacos-server1，nacos-server2，nacos-server3。
主机通过nginx监听8080端口，通过负载均衡将请求转发到三台nacos机器上。
主机作为数据库源，使用mysql作为数据库，端口为3306，三台机器都安装mysql环境，端口运行在3306，映射到主机3307端口。
服务说明 创建一个简单的服务，注册到上述nacos环境中，通过在bootstrap.yaml中读取nacos配置来验证环境是否配置成功。
搭建nacos环境 编辑docker-compose的yaml文件 在nacos官网下载nacos-docker到主机上，编辑example/cluster-hostname.yaml文件。
根据官网说明，在nacos2中需要额外暴露两个端口，分别偏移8848这个端口1000和1001。
1version: &amp;#34;3&amp;#34; 2services: 3 nacos1: 4 hostname: nacos-server-1 5 container_name: nacos1 6 image: nacos/nacos-server:${NACOS_VERSION} 7 volumes: 8 - ./cluster-logs/nacos1:/home/nacos/logs 9 - ./init.d/custom.properties:/home/nacos/init.d/custom.properties 10 ports: 11 - &amp;#34;8848:8848&amp;#34; 12 - &amp;#34;9848:9848&amp;#34; # 偏移1000 13 - &amp;#34;9849:9849&amp;#34; # 偏移1001 14 - &amp;#34;9555:9555&amp;#34; 15 env_file: 16 - ../env/nacos-hostname.env 17 restart: always 18 depends_on: 19 - mysql 20 21 nacos2: 22 hostname: nacos-server-2 23 image: nacos/nacos-server:${NACOS_VERSION} 24 container_name: nacos2 25 volumes: 26 - .</description>
    </item>
    
    <item>
      <title>Zipkin 使用记录</title>
      <link>/posts/2022/07/zipkin-usage-record/</link>
      <pubDate>Fri, 29 Jul 2022 18:26:44 +0800</pubDate>
      
      <guid>/posts/2022/07/zipkin-usage-record/</guid>
      <description>Zipkin的作用 查看微服务调用过程； 分析微服务依赖关系； 方便地找到调用过程错误发生位置。 Zipkin使用记录 一、下载Zipkin并运行：
1java -jar zipkin.jar 这样成功运行后，默认在端口9411可以查看图形管理界面。
二、依赖引入
在所有调用到的微服务中引入：
1&amp;lt;dependency&amp;gt; 2 &amp;lt;groupId&amp;gt;org.springframework.cloud&amp;lt;/groupId&amp;gt; 3 &amp;lt;artifactId&amp;gt;spring-cloud-starter-zipkin&amp;lt;/artifactId&amp;gt; 4&amp;lt;/dependency&amp;gt; 三、配置文件
1spring: 2 zipkin: 3 base-url: http://localhost:9411 4 sleuth: 5 sampler: 6 probability: 1 # 采样率介于0和1之间，1表示全部采集 测试 通过service-name标签搜索自己的微服务名称，即可检索到与该微服务有依赖的所有微服务，可查看调用过程，依赖关系等。
From My Blog: akynazh.
Over.</description>
    </item>
    
    <item>
      <title>SpringCloud-Stream 使用记录</title>
      <link>/posts/2022/07/springcloud-stream-usage-record/</link>
      <pubDate>Fri, 29 Jul 2022 17:26:05 +0800</pubDate>
      
      <guid>/posts/2022/07/springcloud-stream-usage-record/</guid>
      <description>为何使用Stream？ 实现消息的收发可以用许多种方式来实现，如Kafka，RabbitMQ等，而通过Stream可以方便地通过一个Binder对象与这些不同的实现工具对接，应用程序通过Inputs和Outputs来与Binder交互即可实现消息的收发，这样我们就只需要知道如何与Stream交互即可方便地使用消息驱动。
下图即Stream工作原理：
Stream使用记录 一、依赖导入 除去一些基本依赖之外，发布端和订阅端均导入：
1&amp;lt;dependency&amp;gt; 2 &amp;lt;groupId&amp;gt;org.springframework.cloud&amp;lt;/groupId&amp;gt; 3 &amp;lt;artifactId&amp;gt;spring-cloud-starter-stream-rabbit&amp;lt;/artifactId&amp;gt; 4&amp;lt;/dependency&amp;gt; 二、基本配置 发布端：
1spring: 2 cloud: 3 stream: 4 binders: 5 defaultRabbit: 6 type: rabbit 7 environment: 8 spring: 9 rabbitmq: 10 host: localhost 11 port: 5672 12 username: guest 13 password: guest 14 bindings: 15 output: 16 destination: myExchange 17 content-type: application/json 18 binder: defaultRabbit 订阅端：
1spring: 2 cloud: 3 stream: 4 binders: 5 defaultRabbit: 6 type: rabbit 7 environment: 8 spring: 9 rabbitmq: 10 host: localhost 11 port: 5672 12 username: guest 13 password: guest 14 bindings: 15 input: 16 destination: myExchange 17 content-type: application/json 18 binder: defaultRabbit 19 group: jzh1 注意，两个订阅端如果实现同一微服务，group应该一样，这样，在同一个组内会发生竞争关系，只有其中一个可以消费（默认采用轮询的机制处理），避免了出现重复消费的问题。</description>
    </item>
    
    <item>
      <title>Config 结合 Bus 使用记录</title>
      <link>/posts/2022/07/config-combined-with-bus-usage-record/</link>
      <pubDate>Wed, 27 Jul 2022 22:00:55 +0800</pubDate>
      
      <guid>/posts/2022/07/config-combined-with-bus-usage-record/</guid>
      <description>为何要使用Config和Bus Config可以进行多个微服务下的全局配置，更加方便，易于管理。
当全局配置修改时，需要通知各个微服务，一个一个地通知是非常耗时的，如果可以通过广播的方式快速将消息传递出去就轻松多了，而通过Bus即可实现这一点。
测试方法 一、在6996端口通过git拉取全局配置，相当于一个ConfigServer，6886和6776端口作为ConfigClient；
二、Bus结合RabbitMQ实现，修改配置时，只通知ConfigServer，达到消息广播的效果。
依赖引入 一、ConfigServer端：
1&amp;lt;dependency&amp;gt; 2 &amp;lt;groupId&amp;gt;org.springframework.cloud&amp;lt;/groupId&amp;gt; 3 &amp;lt;artifactId&amp;gt;spring-cloud-starter-bus-amqp&amp;lt;/artifactId&amp;gt; 4&amp;lt;/dependency&amp;gt; 5&amp;lt;dependency&amp;gt; 6 &amp;lt;groupId&amp;gt;org.springframework.cloud&amp;lt;/groupId&amp;gt; 7 &amp;lt;artifactId&amp;gt;spring-cloud-config-server&amp;lt;/artifactId&amp;gt; 8&amp;lt;/dependency&amp;gt; 二、ConfigClient端：
1&amp;lt;dependency&amp;gt; 2 &amp;lt;groupId&amp;gt;org.springframework.cloud&amp;lt;/groupId&amp;gt; 3 &amp;lt;artifactId&amp;gt;spring-cloud-starter-bus-amqp&amp;lt;/artifactId&amp;gt; 4&amp;lt;/dependency&amp;gt; 5&amp;lt;dependency&amp;gt; 6 &amp;lt;groupId&amp;gt;org.springframework.cloud&amp;lt;/groupId&amp;gt; 7 &amp;lt;artifactId&amp;gt;spring-cloud-starter-config&amp;lt;/artifactId&amp;gt; 8&amp;lt;/dependency&amp;gt; 其他一些基本包就省略了。
文件配置 一、ConfigServer端：
以下为application.yml:
1spring: 2 cloud: 3 config: 4 server: 5 git: 6 # github项目地址 7 uri: https://github.com/akynazh/SpringCloud-Demo.git 8 # 指定搜索项目下config文件夹中的内容 9 search-paths: 10 - config 11 # 指定分支 12 default-label: master 13 rabbitmq: 14 host: localhost 15 port: 5672 16 username: guest 17 password: guest 18management: 19 endpoints: 20 web: 21 exposure: 22 # 通过/actuator/bus-refresh可进行事件通知 23 include: &amp;#34;bus-refresh&amp;#34; 以后，运维人员修改config时，即可通过如下地址：</description>
    </item>
    
    <item>
      <title>SpringCloud-Gateway 使用记录</title>
      <link>/posts/2022/07/springcloud-gateway-usage-record/</link>
      <pubDate>Tue, 26 Jul 2022 18:33:44 +0800</pubDate>
      
      <guid>/posts/2022/07/springcloud-gateway-usage-record/</guid>
      <description>网关的作用 如图所示，网关介于外部请求和具体微服务之间，在不暴露内部微服务端口的情况下，通过一个或者多个指定的网关端口统一地处理外部各种请求。
使用SpringCloud Gateway 依赖引入 除了基本依赖以外，引入下列依赖：
1&amp;lt;!-- others --&amp;gt; 2&amp;lt;dependency&amp;gt; 3 &amp;lt;groupId&amp;gt;org.springframework.cloud&amp;lt;/groupId&amp;gt; 4 &amp;lt;artifactId&amp;gt;spring-cloud-starter-netflix-eureka-client&amp;lt;/artifactId&amp;gt; 5&amp;lt;/dependency&amp;gt; 6&amp;lt;dependency&amp;gt; 7 &amp;lt;groupId&amp;gt;org.springframework.cloud&amp;lt;/groupId&amp;gt; 8 &amp;lt;artifactId&amp;gt;spring-cloud-starter-gateway&amp;lt;/artifactId&amp;gt; 9&amp;lt;/dependency&amp;gt; 注意不能引入web相关依赖，因为Gateway是基于WebFlux的。
文件配置 列出部分重要配置：
1server: 2port: 9669 3cloud: 4 gateway: 5 discovery: 6 locator: 7 enabled: true # 开启从注册中心动态创建路由的功能，利用微服务名进行路由 8 routes: 9 - id: path_route 10 uri: lb://CLOUD-PAYMENT-SERVICE # lb：负载均衡 11 predicates: 12 - Path=/payment/** 13 - After=2022-07-26T17:33:52.449+08:00[Asia/Shanghai] # ZonedDateTime.now() 14 - Cookie=username,jzh 注意点如下：
9669端口作为网关端口； uri中http改为了lb，用于负载均衡； predicates，即断言，上述断言是： 匹配路径：/payment/**； 开始允许访问时间：ZonedDateTime.now()（Java函数获取该格式时间） 携带cookie：key=username, value=jzh 过滤器配置 实现GlobalFilter, Ordered，重写方法即可：</description>
    </item>
    
    <item>
      <title>Hystrix 实现服务熔断与监控</title>
      <link>/posts/2022/07/hytrix-realizes-service-fusing-and-monitoring/</link>
      <pubDate>Tue, 26 Jul 2022 11:39:11 +0800</pubDate>
      
      <guid>/posts/2022/07/hytrix-realizes-service-fusing-and-monitoring/</guid>
      <description>什么是服务熔断 概念 应对微服务雪崩效应的一种链路保护机制，类似保险丝。
关于雪崩效应 微服务之间的数据交互是通过远程调用来完成的。服务A调用服务，服务B调用服务C，某一时间链路上对服务C的调用响应时间过长或者服务C不可用，随着时间的增长，对服务C的调用也越来越多，然后服务C崩溃了，但是链路调用还在，对服务B的调用也在持续增多，然后服务B崩溃，随之A也崩溃，导致雪崩效应。
实现机制 当某服务出现不可用或响应超时的情况时，为了防止整个系统出现雪崩，暂时停止对该服务的调用。
通过Hystrix实现服务熔断，Hystrix会监控微服务间调用的状况，当失败的调用到一定阈值，就会启动熔断机制，断路器打开。而在一段时间之后，断路器会变为半开状态，此时允许部分微服务调用，如果都成功了，即不超过设定好的阈值，那么断路器将恢复为关闭状态。
如下图所示：（来自Martin Fowler大神的博客）
应用场景 微服务架构中，多个微服务相互调用出使用
Hystrix实现服务熔断 环境搭建 1. 关于pom.xml 1&amp;lt;dependency&amp;gt; 2 &amp;lt;groupId&amp;gt;org.springframework.cloud&amp;lt;/groupId&amp;gt; 3 &amp;lt;artifactId&amp;gt;spring-cloud-starter-netflix-hystrix&amp;lt;/artifactId&amp;gt; 4&amp;lt;/dependency&amp;gt; 5&amp;lt;dependency&amp;gt; 6 &amp;lt;groupId&amp;gt;org.springframework.cloud&amp;lt;/groupId&amp;gt; 7 &amp;lt;artifactId&amp;gt;spring-cloud-starter-netflix-eureka-client&amp;lt;/artifactId&amp;gt; 8&amp;lt;/dependency&amp;gt; 2. 启动类添加@EnableHystrix注解，表示使用熔断器。 实现服务熔断 1. PaymentService.java 1public interface PaymentService { 2 ... 3 String circuitBreaker(Integer id); 4} 2. PaymentServiceImpl.java 设置服务熔断的核心配置：
（1）启用断路器:
1@HystrixProperty(name = &amp;#34;circuitBreaker.enabled&amp;#34;, value = &amp;#34;true&amp;#34;) （2）设置请求次数:
1@HystrixProperty(name = &amp;#34;circuitBreaker.requestVolumeThreshold&amp;#34;, value = &amp;#34;10&amp;#34;) （3）设置时间窗口期:
1@HystrixProperty(name = &amp;#34;circuitBreaker.sleepWindowInMilliseconds&amp;#34;, value = &amp;#34;10000&amp;#34;) （4）设置失败率:
1@HystrixProperty(name = &amp;#34;circuitBreaker.</description>
    </item>
    
    <item>
      <title>Hystrix 实现服务降级</title>
      <link>/posts/2022/07/hytrix-enables-service-degradation/</link>
      <pubDate>Tue, 26 Jul 2022 10:59:08 +0800</pubDate>
      
      <guid>/posts/2022/07/hytrix-enables-service-degradation/</guid>
      <description>什么是服务降级 概念 一般指在服务器压力剧增的时候，根据实际业务使用情况以及流量，对一些服务和页面有策略的不处理或者用一种简单的方式进行处理，从而释放服务器资源的资源以保证核心业务的正常高效运行。
应用场景 多用于微服务架构中，一般当整个微服务架构整体的负载超出了预设的上限阈值（和服务器的配置性能有关系），或者即将到来的流量预计会超过预设的阈值时。
大致实现过程 为了预防某些功能出现负荷过载或者响应慢的情况，在其内部暂时舍弃对一些非核心的接口和数据的请求，而直接返回一个提前准备好的fallback（退路）错误处理信息。这样，虽然提供的是一个有损的服务，但却保证了整个系统的稳定性和可用性。
使用Hystrix实现服务降级 本实验配合了Feign实现，利用Feign通过接口的方式解耦服务这一特点，通过在实现服务接口的类来编写方法对应的fallback方法。
环境搭建 一、关于pom
在消费方实现服务降级，除了基本包导入外，导入以下：
1&amp;lt;dependency&amp;gt; 2 &amp;lt;groupId&amp;gt;org.springframework.cloud&amp;lt;/groupId&amp;gt; 3 &amp;lt;artifactId&amp;gt;spring-cloud-starter-netflix-hystrix&amp;lt;/artifactId&amp;gt; 4&amp;lt;/dependency&amp;gt; 5&amp;lt;dependency&amp;gt; 6 &amp;lt;groupId&amp;gt;org.springframework.cloud&amp;lt;/groupId&amp;gt; 7 &amp;lt;artifactId&amp;gt;spring-cloud-starter-openfeign&amp;lt;/artifactId&amp;gt; 8&amp;lt;/dependency&amp;gt; 9&amp;lt;dependency&amp;gt; 10 &amp;lt;groupId&amp;gt;org.springframework.cloud&amp;lt;/groupId&amp;gt; 11 &amp;lt;artifactId&amp;gt;spring-cloud-starter-netflix-eureka-server&amp;lt;/artifactId&amp;gt; 12&amp;lt;/dependency&amp;gt; 二、关于application.yml
除了基本配置外，以下两个超时时间的配置需要格外注意：
1# 设置feign超时时间（默认为1秒） 2feign: 3hystrix: 4 enabled: true 5client: 6 config: 7 default: 8 ConnectTimeOut: 5000 9 ReadTimeOut: 5000 10# 设置hystrix超时时间（默认为1秒） 11hystrix: 12command: 13 default: 14 execution: 15 isolation: 16 thread: 17 timeoutInMilliseconds: 2000 其他关于Feign的环境配置省略了。
实现服务降级 一、PaymentService.java
在使用了Feign的基础上使用Hystrix功能，指定fallback对应的实现类。
1@Service 2@FeignClient(value = &amp;#34;CLOUD-HYSTRIX-PAYMENT-SERVICE&amp;#34;, fallback = PaymentHystrixService.</description>
    </item>
    
    <item>
      <title>OpenFeign 使用记录</title>
      <link>/posts/2022/07/openfeign-usage-record/</link>
      <pubDate>Fri, 22 Jul 2022 17:39:24 +0800</pubDate>
      
      <guid>/posts/2022/07/openfeign-usage-record/</guid>
      <description>为什么要使用OpenFeign 之前在消费端使用RestTemplate时，每次请求都要进行诸如
1restTemplate.postForObject(PAYMENT_URL + &amp;#34;/payment/create&amp;#34;, payment, CommonResult.class); 这样的调用，需要指定较多参数，当一个接口调用中需要非常多这样的请求时，会比较繁琐，而且这种方式不够抽象。
OpenFegin利用面向接口编程的思想，抽象化，简化了上述操作。
使用OpenFeign 关于pom.xml 1&amp;lt;dependency&amp;gt; 2 &amp;lt;groupId&amp;gt;org.springframework.cloud&amp;lt;/groupId&amp;gt; 3 &amp;lt;artifactId&amp;gt;spring-cloud-starter-openfeign&amp;lt;/artifactId&amp;gt; 4&amp;lt;/dependency&amp;gt; 关于application.yml 除了基本配置内容外，注意以下配置：
1feign: 2# 设置feign客户端超时时间（默认为1秒） 3client: 4 config: 5 default: 6 ConnectTimeOut: 10000 7 ReadTimeOut: 10000 8# 针对每个接口设置日志监控级别 9logging: 10level: 11 com.jzh.springcloud.service.PaymentService: debug # feign日志以什么级别监控端口 编写服务接口 首先在启动类开启@EnableFeignClients注解，接着编写服务接口：
添加@FeignClient注解，值为对应微服务名； 方法对应微服务Controller下的方法即可。 1@Component 2@FeignClient(value = &amp;#34;CLOUD-PAYMENT-SERVICE&amp;#34;) 3public interface PaymentService { 4 @GetMapping(&amp;#34;/payment/get/{id}&amp;#34;) 5 CommonResult&amp;lt;Payment&amp;gt; getPaymentById(@PathVariable(&amp;#34;id&amp;#34;) Long id); 6 7 @PostMapping(&amp;#34;/payment/create&amp;#34;) 8 CommonResult&amp;lt;Integer&amp;gt; createPayment(@RequestBody Payment payment); 9} 调用接口 注入PaymentController接口，然后即可调用它的方法。</description>
    </item>
    
    <item>
      <title>理解 Ribbon 并自己实现负载均衡</title>
      <link>/posts/2022/07/understand-ribbon-and-realize-load-balancing-by-yourself/</link>
      <pubDate>Wed, 20 Jul 2022 17:07:35 +0800</pubDate>
      
      <guid>/posts/2022/07/understand-ribbon-and-realize-load-balancing-by-yourself/</guid>
      <description>负载均衡（LB）是什么 对于用户的某个请求，将有多个相同功能的服务点服务该请求，某个服务点挂了，其他服务点还是可以进行服务，这样就实现了系统的高可用。
关于集中式LB和进程内LB 集中式LB 在服务的消费方和提供方之间使用独立的LB设施，（软硬件均可，软件如Nginx，硬件如F5），由该设施负责把访问请求通过某种策略（可自行指定）转发至服务的提供方。
进程内LB 将LB逻辑集成到消费方，消费方从服务注册中心获知有哪些地址可用，然后自己再从这些地址中选择出一个合适的服务点进行服务。
Ribbon属于进程内LB，它只是一个类库，集成于消费方进程，消费方通过它获取服务提供方的地址。
使用Ribbon实现负载均衡 关于导包 1&amp;lt;dependency&amp;gt; 2 &amp;lt;groupId&amp;gt;org.springframework.cloud&amp;lt;/groupId&amp;gt; 3 &amp;lt;artifactId&amp;gt;spring-cloud-starter-netflix-eureka-client&amp;lt;/artifactId&amp;gt; &amp;lt;!-- 已经包含了ribbon --&amp;gt; 4&amp;lt;/dependency&amp;gt; 注意eureka内置了ribbon。
开启注解 1@Configuration 2public class ApplicationContextConfig { 3 @Bean 4 @LoadBalanced // 赋予负载均衡能力 5 public RestTemplate getRestTemplate() { 6 return new RestTemplate(); 7 } 8} 访问相同服务名地址即可。
修改Ribbon负载均衡规则 所有规则均实现了IRule接口，通过查看接口实现类即可知道规则的种类。
默认是RoundRobinRule（轮询）这一规则。
下面修改为RandomRule（随机）这一规则：
在启动类扫描不到的包下创建规则： 1@Configuration 2public class MyRibbonRule { 3 @Bean 4 public IRule myRule() { 5 return new RandomRule(); 6 } 7} 在启动类指定规则： 1@SpringBootApplication 2@EnableEurekaClient 3@RibbonClient(name=&amp;#34;CLOUD-PAYMENT-SERVICE&amp;#34;, configuration = MyRibbonRule.</description>
    </item>
    
    <item>
      <title>Consul 配置过程及测试</title>
      <link>/posts/2022/07/consul-configuration-process-and-test/</link>
      <pubDate>Tue, 19 Jul 2022 16:34:39 +0800</pubDate>
      
      <guid>/posts/2022/07/consul-configuration-process-and-test/</guid>
      <description>前言 类似于zookeeper和eureka，也起到微服务注册中心的作用, 满足分布式系统中的CP原则，是弱可用性的。
不同于zookeeper和eureka这两种主要由Java编写的语言，它主要由Go语言编写。
配置Consul环境 下载consul，配置环境变量。 运行consul agent -dev开启服务。 默认端口为8500，访问localhost:8500进入管理界面。 编写springcloud服务代码 一、关于pom.xml
除了一些基本包的导入之外，关于consul包的导入：
1&amp;lt;dependency&amp;gt; 2 &amp;lt;groupId&amp;gt;org.springframework.cloud&amp;lt;/groupId&amp;gt; 3 &amp;lt;artifactId&amp;gt;spring-cloud-starter-consul-discovery&amp;lt;/artifactId&amp;gt; 4&amp;lt;/dependency&amp;gt; 二、关于application.yml
1spring: 2 application: 3 name: cloud-consumer-order 4 5 cloud: 6 consul: 7 host: localhost 8 port: 8500 9 discovery: 10 service-name: ${spring.application.name} 三、启动类添加@EnableDiscoveryClient注解。
consul测试 较为简单，访问localhost:8500查看即可。
From My Blog: akynazh.
Over.</description>
    </item>
    
    <item>
      <title>Zookeeper 配置过程与测试</title>
      <link>/posts/2022/07/zookeeper-configuration-process-and-test/</link>
      <pubDate>Tue, 19 Jul 2022 12:00:37 +0800</pubDate>
      
      <guid>/posts/2022/07/zookeeper-configuration-process-and-test/</guid>
      <description>前言 Zookeeper类似于Eureka，起到微服务注册中心的作用，满足分布式系统中的CP原则，是弱可用性的。
配置zookeeper环境 安装zookeeper 下载并解压zookeeper包为zookeeper3.7.1（假设下载的是3.7.1版本）。
然后将zookeeper解压缩到/usr/local/zookeeper3.7.1。
配置参数 一、编辑/conf/zoo.cfg
编辑zookeeper包内配置文件/conf/zoo.cfg（先创建，再将zoo_sample.cfg内容复制到其中）
修改或添加以下内容：
1dataDir=/usr/local/zookeeper3.7.1/dataDir 2dataLogDir=/usr/local/zookeeper3.7.1/dataLogDir 注意同时创建对应文件夹。其中端口号默认为2181，也可以进行修改。
二、 配置环境变量
1# zookeeper 2export ZOOKEEPER_HOME=/usr/local/zookeeper3.7.1 3export PATH=$PATH:$ZOOKEEPER_HOME/bin 接着通过source命令生效。
开启zookeeper连接 （前置条件是已配好java环境）
执行 zkServer.sh start即可。
查看连接情况： 1zkServer.sh status 2 3ZooKeeper JMX enabled by default 4Using config: /usr/local/zookeeper3.7.1/bin/../conf/zoo.cfg 5Client port found: 2181. Client address: localhost. Client SSL: false. 6Mode: standalone 可见已经开启成功了。
客户端进行连接： 执行 zkCli.sh，连接成功后可查看：
1[zk: localhost:2181(CONNECTED) 1] ls / 2[zookeeper] 3[zk: localhost:2181(CONNECTED) 2] get /zookeeper 编写springcloud服务代码 一、关于pom.xml
除了一些基本包的导入之外，关于zookeeper包的导入：
1&amp;lt;dependency&amp;gt; 2 &amp;lt;groupId&amp;gt;org.</description>
    </item>
    
    <item>
      <title>Eureka 配置过程与理解</title>
      <link>/posts/2022/07/eureka-configuration-process-and-understanding/</link>
      <pubDate>Sun, 17 Jul 2022 11:39:35 +0800</pubDate>
      
      <guid>/posts/2022/07/eureka-configuration-process-and-understanding/</guid>
      <description>前言 起到微服务注册中心的作用，满足分布式系统中的AP原则，是弱一致性的。
Eureka微服务架构图 服务接口采用集群模式，8001和8002端口都实现支付接口服务。 用户接口在运行在80端口，调用8001和8002的服务。 注册中心内部也采用集群模式，7001和7002端口都实现注册服务。 引入Eureka依赖说明 client端：
1&amp;lt;dependency&amp;gt; 2 &amp;lt;groupId&amp;gt;org.springframework.cloud&amp;lt;/groupId&amp;gt; 3 &amp;lt;artifactId&amp;gt;spring-cloud-starter-netflix-eureka-client&amp;lt;/artifactId&amp;gt; 4&amp;lt;/dependency&amp;gt; server端：
1&amp;lt;dependency&amp;gt; 2 &amp;lt;groupId&amp;gt;org.springframework.cloud&amp;lt;/groupId&amp;gt; 3 &amp;lt;artifactId&amp;gt;spring-cloud-starter-netflix-eureka-server&amp;lt;/artifactId&amp;gt; 4&amp;lt;/dependency&amp;gt; 7001和7002端口关键配置内容 一、启动类开启注解
1@SpringBootApplication 2@EnableEurekaServer 3public class EurekaMain7001 { 4 public static void main(String[] args) { 5 SpringApplication.run(EurekaMain7001.class, args); 6 } 7} 二、application.yml文件配置
对于7001端口服务：（7002端口类似）
1eureka: 2 instance: 3 hostname: eureka7001.com 4 client: 5 # false 表示不向注册中心注册自己 6 register-with-eureka: false 7 # false 表示自己端就是注册中心，我的职责就是维护服务实例，并不需要去检索服务 8 fetch-registry: false 9 service-url: 10 # 设置与Eureka Server交互的地址查询服务和注册服务都需要依赖这个地址 11 defaultZone: http://eureka7002.</description>
    </item>
    
  </channel>
</rss>